{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name =\"Chakrya Ros\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.bigram  {('<s>', '<UNK>'): 2, ('<UNK>', 'is'): 1, ('is', 'close'): 2, ('close', '</s>'): 2, ('</s>', '<s>'): 5, ('<s>', 'I'): 4, ('I', 'am'): 4, ('am', 'excited'): 2, ('excited', 'for'): 2, ('for', '<UNK>'): 2, ('<UNK>', '</s>'): 2, ('am', 'sad'): 2, ('sad', '<UNK>'): 2, ('<UNK>', 'season'): 2, ('season', 'ended'): 1, ('ended', '</s>'): 2, ('<UNK>', 'ended'): 1, ('season', 'is'): 1, ('<UNK>', '<UNK>'): 1}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class LanguageModel:\n",
    "    def __init__(self, n_gram, is_laplace_smoothing, backoff=None):\n",
    "        self.Ngram = n_gram\n",
    "        self.freq = None\n",
    "        self.word = None\n",
    "        self.Numtokens = None\n",
    "        self.smoothing = is_laplace_smoothing\n",
    "        self.content = None\n",
    "        self.bigram = {}\n",
    "        self.unigramProb = {} # unigram probability dic\n",
    "        self.bigramProb = {} # bigram probability dict\n",
    "        \n",
    "    def train(self, training_file_path):\n",
    "        f = open(training_file_path, \"r\")\n",
    "        self.content = f.read()\n",
    "        f.close()\n",
    "        self.word = self.content.split()\n",
    "       \n",
    "        #count the frequency word in dictionary\n",
    "        self.freq = Counter(self.word)\n",
    "       \n",
    "        \n",
    "#         self.freq['<UNK>'] = 0\n",
    "       \n",
    "        #assign <UNK> to the frequecy word that less than 2\n",
    "        for key, value in list(self.freq.items()):\n",
    "            if value == 1:\n",
    "                self.freq['<UNK>'] += 1\n",
    "                del self.freq[key]\n",
    "\n",
    "        # bigram frequecy word        \n",
    "        for i in range(len(self.word)-1):\n",
    "            if self.word[i] not in list(self.freq):  #check if the first word not in frequency\n",
    "                self.word[i] = '<UNK>'\n",
    "            if self.word[i+1] not in list(self.freq): #check if the next word not in frequency\n",
    "                self.word[i+1] = '<UNK>'\n",
    "            if (self.word[i],self.word[i+1]) not in self.bigram: #check if the first and next word not in frequency\n",
    "                self.bigram[(self.word[i],self.word[i+1])] = 1\n",
    "            else:\n",
    "                self.bigram[(self.word[i],self.word[i+1])] += 1\n",
    "        \n",
    "            #calculate probability of bigram words for generate sentence\n",
    "            self.bigramProb[(self.word[i],self.word[i+1])] = self.bigram[(self.word[i],self.word[i+1])]/sum(self.bigram.values())\n",
    "\n",
    "        #count the number of tokens\n",
    "        self.Numtokens = sum(self.freq.values())\n",
    "#         print(\"self.freq \",len(self.freq))\n",
    "#         print(self.Numtokens)\n",
    "        print(\"self.bigram \",self.bigram)\n",
    "        \n",
    "        #calculate probability of each word for generate sentence\n",
    "        for word in self.word:\n",
    "            self.unigramProb[word] = self.freq[word]/sum(self.freq.values())\n",
    "         \n",
    "        \n",
    "        \n",
    "\n",
    "    #helper function for calculate the bigram probability for each bigram\n",
    "    def bigram_probability(self,bigram):\n",
    "        prob = 0\n",
    "        count_word = 0.0\n",
    "        bottom = 0.0\n",
    "        if self.smoothing:\n",
    "            for i in range(len(bigram)-1):\n",
    "                if (bigram[i], bigram[i+1]) not in self.bigram: #check if bigram word not in bigram frequecy\n",
    "                    count_word = 1     #count word zero, just add_smooth\n",
    "                else:\n",
    "                    #if self_bigram has bigram word, get the values and add_smooth\n",
    "                    count_word = self.bigram[bigram[i],bigram[i+1]] + 1\n",
    "                if bigram[i] not in self.freq:  #check for single word\n",
    "                    bottom = 1\n",
    "                else:\n",
    "                    bottom = self.freq[bigram[i]] + len(self.freq)\n",
    "#             print(\"bigram {} {}\".format(bigram, prob))\n",
    "            prob = count_word/bottom\n",
    "            \n",
    "           \n",
    "        else:\n",
    "            for i in range(len(bigram)-1):\n",
    "                if (bigram[i], bigram[i+1]) not in self.bigram: #check if bigram word not in bigram frequecy\n",
    "                    prob = 0.0\n",
    "#                 if (bigram[i+1]) not in self.freq:  #check for single word\n",
    "#                     prob = 0.0\n",
    "#                 if bigram[i] not in self.freq:\n",
    "#                     prob = 0.0\n",
    "                else:\n",
    "                    prob = self.bigram[bigram]/self.freq[bigram[0]]\n",
    "            print(prob)\n",
    "        return prob\n",
    "       \n",
    "    #helper function for calculate the unigram probability for each word\n",
    "    def unigram_probability(self,word):\n",
    "        prob = 0\n",
    "        if self.smoothing:\n",
    "            prob = (self.freq[word] + 1)/(self.Numtokens + len(self.freq))\n",
    "#             print(\"unigram {} {}\".format(word, prob))\n",
    "           \n",
    "        else:\n",
    "            prob = (self.freq[word])/(self.Numtokens)\n",
    "#             print(\"unigram {} {}\".format(word, prob))\n",
    "           \n",
    "        return prob  \n",
    "        \n",
    "    #helper function for generate unigram random\n",
    "    def unigram_generate(self):\n",
    "        start = '<s>'\n",
    "        word_freqs = []\n",
    "        word_freqs.append(start)\n",
    "      \n",
    "        #check if the word is not the end of sentence\n",
    "        while start != '</s>':\n",
    "            unigram_freqs = {}\n",
    "            #loop through frequecy words\n",
    "            for w in list(self.freq.keys()):\n",
    "                if w != '<s>':\n",
    "                    unigram_freqs[w] = self.unigramProb[w]  #calcutate the probability word\n",
    "            total = sum(unigram_freqs.values())    # calcuate the total of frequence word values   \n",
    "            for i in list(unigram_freqs.keys()):\n",
    "                unigram_freqs[i] = unigram_freqs[i]/total\n",
    "            #generate the random word in the range of probability\n",
    "            random_word = random.choices(list(unigram_freqs.keys()), list(unigram_freqs.values()))\n",
    "            word_freqs.append(random_word[0])\n",
    "            while word_freqs[1] == '</s>':\n",
    "                word_freqs.pop()\n",
    "                random_word = random.choices(list(unigram_freqs.keys()), list(unigram_freqs.values()))\n",
    "                word_freqs.append(random_word[0])\n",
    "            start = random_word[0]\n",
    "        word_freqs = ' '.join(word_freqs)\n",
    "        return word_freqs\n",
    "    \n",
    "    def bigram_genterate(self):\n",
    "        start = '<s>'\n",
    "        sentence = []\n",
    "        sentence.append('<s>')\n",
    "        #check if the word is not the end of sentence\n",
    "        while start != '</s>':\n",
    "            bigram_freqs = {}\n",
    "            #loop through frequecy words\n",
    "            for word in list(self.bigramProb.keys()):\n",
    "                if word[0] == start:\n",
    "                    #calcutate the probability bigram word\n",
    "                    bigram_freqs[word] = self.bigramProb[word]\n",
    "\n",
    "#             total = sum(bigram_freqs.values())\n",
    "#             for word in bigram_freqs:\n",
    "#                 bigram_freqs[word] = bigram_freqs[word]/total\n",
    "            #random select word from bigram frequence\n",
    "            keys=np.array(list(bigram_freqs.keys()))\n",
    "            prob=np.array(list(bigram_freqs.values()))\n",
    "            prob/= prob.sum()\n",
    "            index = np.random.choice(len(keys),1,p=prob)\n",
    "            word=keys[index]\n",
    "            word=keys[np.random.choice(len(keys),1,p=prob)]\n",
    "#             word = random.choices(list(bigram_freqs.keys()), list(bigram_freqs.values()))\n",
    "            sentence.append(word[0][1])\n",
    "            start = word[0][1]\n",
    "\n",
    "        sentence = \" \".join(sentence)\n",
    "        return sentence\n",
    "   \n",
    "            \n",
    "    # generate the random sentence\n",
    "    def generate(self, num_sentences):\n",
    "        arr_sentences = []\n",
    "        sentence = ''\n",
    "        for _ in range(num_sentences):\n",
    "            if self.Ngram == 1:\n",
    "                sentence = self.unigram_generate() #generate the unigram sentence\n",
    "                arr_sentences.append(sentence)\n",
    "            else:\n",
    "                sentence = self.bigram_genterate() #generate the bigram sentence\n",
    "                arr_sentences.append(sentence)\n",
    "        return arr_sentences\n",
    "            \n",
    "\n",
    "       \n",
    "    #calcuate the probability of each sentence\n",
    "    def score(self, sentence):\n",
    "        prob =1.0\n",
    "        sentence = sentence.split()\n",
    "        #calculate the probability of unigram\n",
    "        if self.Ngram == 1:\n",
    "            for i in range(len(sentence)):\n",
    "                if sentence[i] not in self.freq:\n",
    "                    sentence[i] = '<UNK>'\n",
    "            \n",
    "            for word in sentence:\n",
    "                prob = prob * self.unigram_probability(word)\n",
    "                \n",
    "#             print(\"unigra_score\", sentence)\n",
    "#             print(\"len(words)\", len(sentence))\n",
    "        #calculate the probability of bigram\n",
    "        else:\n",
    "            \n",
    "            for i in range(len(sentence)-1):\n",
    "                if sentence[i] not in self.freq:\n",
    "                    sentence[i] = '<UNK>'\n",
    "                if sentence[i+1] not in self.freq:\n",
    "                    sentence[i+1] = '<UNK>'\n",
    "                sentence[i] = (sentence[i], sentence[i+1])\n",
    "            \n",
    "            for w in sentence:\n",
    "                prob = prob * self.bigram_probability(w)\n",
    "                \n",
    "        return prob\n",
    "    \n",
    "    #helper function to write probabiliy to file\n",
    "    def prob_to_file(self, test_file, outfile):\n",
    "        file = open(test_file)\n",
    "        #read each line of file\n",
    "        lines = file.readlines()\n",
    "        lines.pop(-1)\n",
    "        #open file to write probability to file\n",
    "        out = open(outfile, 'w')\n",
    "        for sentence in lines:\n",
    "            #caculate the probability of unigram\n",
    "            prob = self.score(sentence)\n",
    "            out.write(str(prob) +\"\\n\")\n",
    "        file.close()\n",
    "        out.close()\n",
    "        \n",
    "    def plot_histogram(self, test_file, my_test_set, savefile):\n",
    "        hw_file_test = open(test_file)\n",
    "        sentence_test = hw_file_test.readlines()\n",
    "        prob_hw_test = []\n",
    "        sentence_test.pop(-1)\n",
    "        for sentence in sentence_test:\n",
    "            prob_hw_test.append(self.score(sentence))\n",
    "        \n",
    "        myFile = open(my_test_set)\n",
    "        sentence_mytest = myFile.readlines()\n",
    "        prob_my_test = []\n",
    "        sentence_mytest.pop(-1)\n",
    "        for s in sentence_mytest:\n",
    "            prob_my_test.append(self.score(s))\n",
    "        hw_file_test.close()\n",
    "        myFile.close()\n",
    "        concate_list = prob_hw_test + prob_my_test\n",
    "        overall_min = min(concate_list)\n",
    "        #plot the histogram\n",
    "        min_exponent = np.floor(np.log10(np.abs(overall_min)))\n",
    "        plt.hist([prob_hw_test,prob_my_test],bins=np.logspace(np.log10(10**min_exponent),\n",
    "                            np.log10(1.0)), label = [\"hw2-test\", \"My test set\"], stacked = True) \n",
    "        plt.title(\"The relative frequency of the probabilities of the test set\")\n",
    "        plt.xlabel(\"Probability of test set\")\n",
    "        plt.ylabel(\"Frequecy\")\n",
    "        plt.legend()\n",
    "        plt.savefig(savefile,bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "    #extra credit to calculate the perplexity\n",
    "    def perplexity(self,test_sequence):\n",
    "        file = open(test_sequence)\n",
    "        word = file.read()\n",
    "        sentences = file.readlines()\n",
    "        word = word.split()\n",
    "        NumWord = len(word)\n",
    "        per_log_sum = 0\n",
    "        perplex = 0\n",
    "        for s in sentences:\n",
    "            per_log_sum -= math.log(self.score(s),2)\n",
    "        perplex = math.pow(2, (per_log_sum/NumWord))\n",
    "        return perplex\n",
    "            \n",
    "           \n",
    "        \n",
    "def main():\n",
    "    #Unigram model\n",
    "    LM = LanguageModel(1, True, backoff=None)\n",
    "#     LM.train('berp-training.txt')\n",
    "    LM.train('hw2-minitest.txt')\n",
    "    random_sentences = LM.generate(2)\n",
    "    generate_file = open(\"final_unigram-generated.txt\", 'w')\n",
    "    for sentence in random_sentences:\n",
    "        generate_file.write(str(sentence) + '\\n')\n",
    "    generate_file.close()\n",
    "#     LM.prob_to_file(\"hw2-test.txt\",\"hw2-unigram-out.txt\")\n",
    "#     LM.plot_histogram(\"hw2-test.txt\",\"hw2-my-test.txt\", \"hw2-unigram-histogram.pdf\")\n",
    "\n",
    "    \n",
    "    #bigram model\n",
    "#     LM_bigram = LanguageModel(2, False, backoff=None)\n",
    "#     LM_bigram.train('berp-training.txt')\n",
    "#     LM_bigram.train('hw2-minitest.txt')\n",
    "#     random_bigram = LM_bigram.generate(2)\n",
    "#     print(LM_bigram.score('<s> sam i ham </s>'))\n",
    "#     generate_bigram = open(\"hw2-bigram-generated.txt\", 'w')\n",
    "#     for sentence in random_bigram:\n",
    "#         generate_bigram.write(str(sentence) + '\\n')\n",
    "#     generate_bigram.close()\n",
    "#     LM_bigram.prob_to_file(\"hw2-test.txt\",\"hw2-bigram-out.txt\")\n",
    "#     LM_bigram.plot_histogram(\"hw2-test.txt\",\"hw2-my-test.txt\", \"hw2-bigram-histogram.pdf\")\n",
    "#     test_perplex = open(\"hw2-minitest.txt\", 'r')\n",
    "#     print(LM.perplexity(\"hw2-minitest.txt\"))\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "                             \n",
    "                \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    main()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.805\n"
     ]
    }
   ],
   "source": [
    "p = (2.5*3) + (-5*2) + (-1.2*1)+ (0.5*3) + (2*0)+(.7*4.15) + 0.1\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6910430124157229\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(1/(1+np.exp(-p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9299999999999999, -0.62, -0.31, -0.9299999999999999, -0.0, -1.2865000000000002]\n"
     ]
    }
   ],
   "source": [
    "x = [3,2,1,3,0,4.15]\n",
    "w = []\n",
    "for i in x:\n",
    "    w.append((-0.31)*i)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.43, -4.38, -0.8899999999999999, 1.4300000000000002, 2, 1.99]\n"
     ]
    }
   ],
   "source": [
    "#compute gradient\n",
    "w_t = [2.5, -5, -1.2, 0.5,2,0.7]\n",
    "gre = [-0.93, -0.62,-.31,-0.93, 0,-1.29]\n",
    "w_t_1 = []\n",
    "for i in range(len(w_t)):\n",
    "   \n",
    "    p = w_t[i]-gre[i]\n",
    "        \n",
    "    w_t_1.append(p)\n",
    "print(w_t_1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.288500000000004\n",
      "0.9999983061418364\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature = [3,2,1,3,0,4.15]\n",
    "z = np.dot(feature,w_t_1) + 0.1\n",
    "print(z)\n",
    "print(1/(1+np.exp(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "P(y=1|x) = 0.6792\n",
      "0.679178699175393\n"
     ]
    }
   ],
   "source": [
    "#quiz 5\n",
    "import numpy as np\n",
    "import math\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + math.exp(-x))\n",
    "\n",
    "x = [1,1,3]\n",
    "w=[0,-2,0.75]\n",
    "b = 0.5\n",
    "z = (np.dot(x,w)) + b\n",
    "print(z)\n",
    "p_y_1 = 1/(1+np.exp(-z))\n",
    "print(\"P(y=1|x) = {:.04f}\".format(p_y_1))\n",
    "\n",
    "print(sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient = [-0.320821300824607, -0.320821300824607, -0.9624639024738211]\n",
      "w_t_1 = [0.320821300824607, -1.679178699175393, 1.712463902473821]\n",
      "p_y_1 from updat weight = 0.9863333296044556\n"
     ]
    }
   ],
   "source": [
    "#calculate the value of \n",
    "#w_t+1 = w_t - learningrate*gradients\n",
    "#gradient = [sigmoid(w*x+b)-y]x_j\n",
    "def gradient(x,z,y=1):\n",
    "    grad = []\n",
    "    temp  = z-y\n",
    "    for i in x:\n",
    "        grad.append(temp*i)\n",
    "    return grad\n",
    "grad = gradient(x,p_y_1,1)\n",
    "print(\"gradient = {}\".format(grad))\n",
    "w_t_1= []\n",
    "for i in range(len(grad)):\n",
    "    w_t_1.append(w[i]-(1*grad[i]))\n",
    "print(\"w_t_1 = {}\".format(w_t_1))\n",
    "\n",
    "#calculate p_y_1 from update weight\n",
    "z_new = np.dot(x,w_t_1)+b\n",
    "print(\"p_y_1 from updat weight = {}\".format(sigmoid(z_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.820821300824607\n",
      "0.9900467753908733\n"
     ]
    }
   ],
   "source": [
    "p = sigmoid(z_new)\n",
    "dz = p_y_1 - 1\n",
    "b_1 = b - (1*dz)\n",
    "print(b_1)\n",
    "# print(((1/2)*dz))\n",
    "z_new = (np.dot(x,w_t_1)) + b_1\n",
    "print(sigmoid(z_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_t_1_new = [0.032082130082460705, -1.9679178699175393, 0.8462463902473821]\n",
      "p_y_1 from updat weight = 0.7508037257111576\n",
      "b_1_new  0.5320821300824607\n",
      "0.2432422072374817\n",
      "0.7567577927625183\n"
     ]
    }
   ],
   "source": [
    "x = [1,1,3]\n",
    "w = [0,-2,0.75]\n",
    "b = 0.5\n",
    "z = (np.dot(x,w)) + b\n",
    "p_y_1 = sigmoid(z)\n",
    "def gradient(x,z,y=1):\n",
    "    grad = []\n",
    "    temp  = z-y\n",
    "    for i in x:\n",
    "        grad.append(temp*i)\n",
    "    return grad\n",
    "\n",
    "grad = gradient(x,p_y_1,1)\n",
    "\n",
    "w_t_1_new = []\n",
    "for i in range(len(grad)):\n",
    "    w_t_1_new.append(w[i]-(0.1*grad[i]))\n",
    "print(\"w_t_1_new = {}\".format(w_t_1_new))\n",
    "\n",
    "#calculate p_y_1 from update weight\n",
    "z_new0 = np.dot(x,w_t_1_new)+0.5\n",
    "print(\"p_y_1 from updat weight = {}\".format(sigmoid(z_new0)))\n",
    "p0 = sigmoid(z_new0)\n",
    "dz = p_y_1 - 1\n",
    "b_1_new = 0.5 - (0.1*dz)\n",
    "print(\"b_1_new \", b_1_new)\n",
    "# print(((1/2)*dz))\n",
    "z_new_0 = np.dot(x,w_t_1_new) + b_1_new\n",
    "print(1-sigmoid(z_new_0))\n",
    "print(sigmoid(z_new_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0, 3.25, -0.625]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2ae709ce8882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mw_t_1_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mw_t_1_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"w_t_1_new = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_t_1_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'float'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "x = [3, 0.75]\n",
    "w = [[1, 0],\n",
    "     [2, -3],\n",
    "     [0, 0.5]]\n",
    "b =[1, -0.5, -1]\n",
    "z = []\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + math.exp(-x))\n",
    "for i in range(len(w)):\n",
    "    z.append((np.dot(x,w[i])) + b[i])\n",
    "print(z)\n",
    "\n",
    "\n",
    "# p_y_1 = sigmoid(z)\n",
    "# def gradient(x,z,y=1):\n",
    "#     grad = []\n",
    "#     temp  = z-y\n",
    "#     for i in x:\n",
    "#         grad.append(temp*i)\n",
    "#     return grad\n",
    "\n",
    "# grad = gradient(x,0.373,1)\n",
    "\n",
    "# w_t_1_new = []\n",
    "# for i in range(len(grad)):\n",
    "#     w_t_1_new.append(w[i]-(0.1*grad[i]))\n",
    "# print(\"w_t_1_new = {}\".format(w_t_1_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
