{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-9-4c611fcffc8e>, line 45)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-4c611fcffc8e>\"\u001b[0;36m, line \u001b[0;32m45\u001b[0m\n\u001b[0;31m    current = []\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Your name and file comment here:\n",
    "    Chakrya Ros\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Cite your sources here:\n",
    "\"\"\"\n",
    "\n",
    "def generate_tuples_from_file(file_path):\n",
    "      \"\"\"\n",
    "      Implemented for you. \n",
    "\n",
    "      counts on file being formatted like:\n",
    "      1 Comparison  O\n",
    "      2 with  O\n",
    "      3 alkaline  B\n",
    "      4 phosphatases  I\n",
    "      5 and O\n",
    "      6 5 B\n",
    "      7 - I\n",
    "      8 nucleotidase  I\n",
    "      9 . O\n",
    "\n",
    "      1 Pharmacologic O\n",
    "      2 aspects O\n",
    "      3 of  O\n",
    "      4 neonatal  O\n",
    "      5 hyperbilirubinemia  O\n",
    "      6 . O\n",
    "\n",
    "      params:\n",
    "        file_path - string location of the data\n",
    "      return:\n",
    "        a list of lists of tuples in the format [[(token, label), (token, label)...], ...]\n",
    "      \"\"\"\n",
    "    current = []\n",
    "    f = open(file_path, \"r\", encoding=\"utf8\")\n",
    "    examples = []\n",
    "    for line in f:\n",
    "        if len(line.strip()) == 0 and len(current) > 0:\n",
    "            examples.append(current)\n",
    "            current = []\n",
    "        else:\n",
    "            pieces = line.strip().split()\n",
    "            current.append(tuple(pieces[1:]))\n",
    "    if len(current) > 0:   # THESE LINES WERE MISSING\n",
    "        examples.append(current)   # THESE LINES WERE MISSING\n",
    "    f.close()\n",
    "    return examples\n",
    "\n",
    "\n",
    "def get_words_from_tuples(examples):\n",
    "  \"\"\"\n",
    "  You may find this useful for testing on your development data.\n",
    "\n",
    "  params:\n",
    "    examples - a list of tuples in the format [(token, label), (token, label)...]\n",
    "  return:\n",
    "    a list of lists of tokens\n",
    "  \"\"\"\n",
    "    return [[t[0] for t in example] for example in examples]\n",
    "\n",
    "\n",
    "def decode(data, probability_table, pointer_table):\n",
    "  \"\"\"\n",
    "  TODO: implement\n",
    "  params: \n",
    "    data - a list of tokens\n",
    "    probability_table - a list of dictionaries of states to probabilities, \n",
    "      one dictionary per word in the test data that represents the\n",
    "      probability of being at that state for that word\n",
    "    pointer_table - a list of dictionaries of states to states, \n",
    "      one dictionary per word in the test data that represents the \n",
    "      backpointers for which previous state led to the best probability\n",
    "      for the current state\n",
    "  return:\n",
    "    a list of tuples in the format [(token, label), (token, label)...]\n",
    "  \"\"\"\n",
    "  pass\n",
    "\n",
    "\n",
    "def precision(gold_labels, classified_labels):\n",
    "  \"\"\"\n",
    "  TODO: implement\n",
    "  params:\n",
    "    gold_labels - a list of tuples in the format [(token, label), (token, label)...]\n",
    "    classified_labels - a list of tuples in the format [(token, label), (token, label)...]\n",
    "  return:\n",
    "    float value of precision at the entity level\n",
    "  \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def recall(gold_labels, classified_labels):\n",
    "  \"\"\"\n",
    "  TODO: implement\n",
    "  params:\n",
    "    gold_labels - a list of tuples in the format [(token, label), (token, label)...]\n",
    "    classified_labels - a list of tuples in the format [(token, label), (token, label)...]\n",
    "  return:\n",
    "    float value of recall at the entity level\n",
    "  \"\"\"\n",
    "    pass\n",
    "\n",
    "def f1(gold_labels, classified_labels):\n",
    "  \"\"\"\n",
    "  TODO: implement\n",
    "  params:\n",
    "    gold_labels - a list of tuples in the format [(token, label), (token, label)...]\n",
    "    classified_labels - a list of tuples in the format [(token, label), (token, label)...]\n",
    "  return:\n",
    "    float value of f1 at the entity level\n",
    "  \"\"\"\n",
    "    prec = precision(gold_labels, classified_labels)\n",
    "    recal = recall(gold_labels, classified_labels)\n",
    "    f1 = 2 * ((prec*recal)/(prec+recal))\n",
    "    return f1\n",
    "\n",
    "def pretty_print_table(data, list_of_dicts):\n",
    "  \"\"\"\n",
    "  Pretty-prints probability and backpointer lists of dicts as nice tables.\n",
    "  Truncates column header words after 10 characters.\n",
    "  params:\n",
    "    data - list of words to serve as column headers\n",
    "    list_of_dicts - list of dicts with len(data) dicts and the same set of\n",
    "      keys inside each dict\n",
    "  return: None\n",
    "  \"\"\"\n",
    "  # ensure that each dict has the same set of keys\n",
    "    keys = None\n",
    "    for d in list_of_dicts:\n",
    "        if keys is None:\n",
    "            keys = d.keys()\n",
    "        else:\n",
    "            if d.keys() != keys:\n",
    "            print(\"Error! not all dicts have the same keys!\")\n",
    "            return\n",
    "    header = \"\\t\" + \"\\t\".join(['{:11.10s}']*len(data))\n",
    "    header = header.format(*data)\n",
    "    rows = []\n",
    "    for k in keys:\n",
    "        r = k + \"\\t\"\n",
    "        for d in list_of_dicts:\n",
    "            if type(d[k]) is float:\n",
    "                r += '{:.9f}'.format(d[k]) + \"\\t\"\n",
    "            else:\n",
    "                r += '{:10.9s}'.format(str(d[k])) + \"\\t\"\n",
    "        rows.append(r)\n",
    "    print(header)\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "\n",
    "\"\"\"\n",
    "Implement any other non-required functions here\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Implement the following class\n",
    "\"\"\"\n",
    "class NamedEntityRecognitionHMM:\n",
    "    def __init__(self):\n",
    "        # TODO: implment as needed\n",
    "        self.vocab_list = Counter()\n",
    "        self.pi = Counter()\n",
    "        self.NumClass = Counter()\n",
    "        self.prior = {}               #initial probability distribution over states\n",
    "        self.emision = Counter()      #a sequency of observation likelihood or emission probabilty\n",
    "        self.transition = Counter()   # probability of state given previous state\n",
    "\n",
    "\n",
    "    def train(self, examples):\n",
    "    \"\"\"\n",
    "    Trains this model based on the given input data\n",
    "    params: examples - a list of lists of (token, label) tuples\n",
    "    return: None\n",
    "    \"\"\"\n",
    "        sentenceCount = 0\n",
    "        for sentence in examples:\n",
    "            for i in range(len(sentence)):\n",
    "                word = sentence[i][0]\n",
    "                state = sentence[i][1]\n",
    "                self.vocab.add(word)\n",
    "                if i==0:\n",
    "                    self.pi[state] +=1\n",
    "                else:\n",
    "                    '''\n",
    "                        p(t_i | t_{i - 1}) = count(t_i - 1, t_i) / count(t_i - 1)\n",
    "                        transitions[prev_state][state] = count(t_i - 1, t_i)\n",
    "                    '''\n",
    "                    if sentence[i-1][1] not in self.transitions:\n",
    "                        self.transitions[sentence[i-1][1]] = Counter()\n",
    "\n",
    "                    self.transitions[sentence[i-1][1]][state] +=1\n",
    "\n",
    "                '''\n",
    "                    p(w_i | t_i) = count(t_i, w_i) / count(t_i)\n",
    "                    emissions[state][word] = count(t_i, w_i)\n",
    "                    sum(emissions[state].values()) = count(t_i)\n",
    "                '''\n",
    "                if state not in self.emissions:\n",
    "                    self.emissions[state] = Counter()\n",
    "                self.emissions[state][word] +=1\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    # print(self.pi)\n",
    "    # print(self.transitions)\n",
    "    # print(self.emissions)\n",
    "    # print(len(self.vocab))\n",
    "\n",
    "    \n",
    "\n",
    "    # count(sentences that start with state) / count of sentences\n",
    "    # for state in self.pi:\n",
    "    #     self.pi_prob[state] = self.pi[state]/sentenceCount\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def generate_probabilities(self, data): \n",
    "        \"\"\"\n",
    "        params: data - a list of tokens\n",
    "        return: two lists of dictionaries --\n",
    "          - first a list of dictionaries of states to probabilities, \n",
    "          one dictionary per word in the test data that represents the\n",
    "          probability of being at that state for that word\n",
    "          - second a list of dictionaries of states to states, \n",
    "          one dictionary per word in the test data that represents the \n",
    "          backpointers for which previous state led to the best probability\n",
    "          for the current state\n",
    "        \"\"\"\n",
    "        first_list_state_prob = []\n",
    "        second_list_state_state = []\n",
    "        prev_prob = 0 \n",
    "        prev_state = None\n",
    "        for i in range(len(data)):\n",
    "            word = data[i]\n",
    "            max_prob = 0\n",
    "            max_state = None\n",
    "            dict_prob_emssion = {}\n",
    "            dict_state_state = {}\n",
    "            for state in self.emissions.keys():\n",
    "                if word in self.emissions[state]:\n",
    "                    emission = (self.emissions[state][word] + 1) / (sum(self.emissions[state].values()) + len(self.vocab))\n",
    "                else:\n",
    "                    emission = ( 0 + 1) / (sum(self.emissions[state].values()) + len(self.vocab))\n",
    "                if i==0:\n",
    "                    #pi * emssion probability\n",
    "                    pi_val = self.pi[state] / sum(self.pi.values())\n",
    "                    prob = emission * pi_val\n",
    "                    dict_prob_emssion[state] = prob\n",
    "                        # print(state)\n",
    "                    dict_state_state[state] = None\n",
    "                else:\n",
    "                    transition = self.transitions[prev_state][state] / sum(self.transitions[prev_state].values())\n",
    "                    prob = prev_prob * transition * emission\n",
    "                    dict_prob_emssion[state] = prob\n",
    "                    dict_state_state[state] = max_state\n",
    "                if max_state is None or prob > max_prob:\n",
    "                    max_state = state\n",
    "                    max_prob = prob\n",
    "\n",
    "            first_list_state_prob.append(dict_prob_emssion)\n",
    "            second_list_state_state.append(dict_state_state)\n",
    "            prev_prob = max_prob\n",
    "            prev_state = max_state\n",
    "\n",
    "        \n",
    "        # print(second_list_state_state)\n",
    "        return first_list_state_prob, second_list_state_state\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"HMM\"\n",
    "\n",
    "\"\"\"\n",
    "Implement the following class\n",
    "\"\"\"\n",
    "class NamedEntityRecognitionMEMM:\n",
    "    def __init__(self):\n",
    "    # implement as needed\n",
    "    pass\n",
    "\n",
    "    def train(self, examples):\n",
    "        \"\"\"\n",
    "        Trains this model based on the given input data\n",
    "        params: examples - a list of lists of (token, label) tuples\n",
    "        return: None\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def featurize(self, data):\n",
    "        \"\"\"\n",
    "        CHOOSE YOUR OWN PARAMS FOR THIS FUNCTION\n",
    "        convert a list of tokens to a list of (feature, value) tuples\n",
    "\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def generate_probabilites(self, data):\n",
    "        pass\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"MEMM\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 3:\n",
    "        print(\"Usage:\", \"python hw5_ner.py training-file.txt testing-file.txt\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    training = sys.argv[1]\n",
    "    testing = sys.argv[2]\n",
    "    training_examples = generate_tuples_from_file(training)\n",
    " \n",
    "    testing_examples = generate_tuples_from_file(testing)\n",
    "\n",
    "  # instantiate each class, train it on the training data, and \n",
    "  # evaluate it on the testing data\n",
    "\n",
    "    NER_HMM = NamedEntityRecognitionHMM()\n",
    "    NER_HMM.train(training_examples)\n",
    "#   data = ['Comparison', 'in', 'alkaline', 'in', '5', '-', 'nucleotidase', 'nucleotidase', '.']\n",
    "#   NER_HMM.generate_probabilities(data)\n",
    "\n",
    "# 1 Comparison  O\n",
    "# 2 in  O\n",
    "# 3 alkaline  B\n",
    "# 4 phosphatases  I\n",
    "# 5 in O\n",
    "# 6 5 B\n",
    "# 7 - I\n",
    "# 8 nucleotidase I\n",
    "# 9 . O\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
