{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-gram investigations & Byte-Pair Encoding\n",
    "-------------------------\n",
    "CSCI 3832, Spring 2020, Muzny, 1/29/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nlp_secrets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8d7cca0bc0ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# this is a module that I have written to hide some implementations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# that you'll need to implement for HW 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnlp_secrets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nlp_secrets'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# this is a module that I have written to hide some implementations\n",
    "# that you'll need to implement for HW 2\n",
    "import nlp_secrets\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens:  1110730\n",
      "number of unique tokens:  35252\n"
     ]
    }
   ],
   "source": [
    "data = \"shakes.txt\"\n",
    "f = open(data, \"r\")\n",
    "content = f.read()\n",
    "f.close()\n",
    "#tokens = content.split()\n",
    "tokens = nltk.word_tokenize(content)\n",
    "print(\"number of tokens: \", len(tokens))\n",
    "print(\"number of unique tokens: \" , len(set(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram counts: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'create_ngrams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-03448d97a065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%i-gram counts: \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mngrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtotals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_ngrams' is not defined"
     ]
    }
   ],
   "source": [
    "xs = []\n",
    "totals = []\n",
    "uniques = []\n",
    "possibles = []\n",
    "for i in range(1, 4):\n",
    "    print(\"%i-gram counts: \" % i)\n",
    "    ngrams = trigrams = create_ngrams(tokens, i)\n",
    "    xs.append(i)\n",
    "    totals.append(len(ngrams))\n",
    "    uniques.append(len(set(ngrams)))\n",
    "    possibles.append(pow(len(ngrams), i))\n",
    "    print(\"total number:\", len(ngrams))\n",
    "    print(\"unique types:\", len(set(ngrams)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xs, totals, label = \"total (N)\")\n",
    "plt.plot(xs, uniques, label = \"unique (V)\")\n",
    "plt.plot(xs, possibles, label = \"possible (V^n_gram)\")\n",
    "plt.yscale('log')\n",
    "plt.legend() # actually show the labels\n",
    "plt.xlabel(\"n-gram order\")\n",
    "plt.ylabel(\"n-grams produced\")\n",
    "plt.title(\"Order of N-grams in comparison with the number possible, unique, and total produced by Shakespeare\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# byte-pair encoding, figure 2.12 in SLP 3\n",
    "import re\n",
    "import collections\n",
    "\n",
    "def get_stats(vocab):\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols) - 1):\n",
    "            pairs[symbols[i], symbols[i + 1]] += freq\n",
    "    return pairs\n",
    "\n",
    "def merge_vocab(pair, v_in):\n",
    "    v_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in v_in:\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = v_in[word]\n",
    "    return v_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-37e1e4ce30e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmerges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_merges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_stats' is not defined"
     ]
    }
   ],
   "source": [
    "vocab = {'l o w </w>': 5, 'l o w e s t </w>': 2, 'n e w e r </w>': 6, 'w i d e r </w>': 3, 'n e w </w>': 2}\n",
    "num_merges = 8\n",
    "merges = []\n",
    "for i in range(num_merges):\n",
    "    pairs = get_stats(vocab)\n",
    "    best = max(pairs, key=pairs.get)\n",
    "    vocab = merge_vocab(best, vocab)\n",
    "    merges.append(''.join(best))\n",
    "    print(i)\n",
    "    print(best)\n",
    "    print(vocab)\n",
    "    print()\n",
    "    \n",
    "# this list as the merges that we applied, in the order that we applied them\n",
    "print(merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0.004279298001297885\n",
      "0.004279298001297885\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "seten = \"0000003000\"\n",
    "w = len(seten)\n",
    "print(w)\n",
    "result = 1.0\n",
    "for i in range(w):\n",
    "    if seten[i] =='0':\n",
    "        result *= 91/100\n",
    "        \n",
    "    else:\n",
    "        result *=1/100\n",
    "print(result)\n",
    "x= (91.0/100)*(91.0/100)*(91.0/100)*(91.0/100)*(91.0/100)*(91.0/100)*(91.0/100)*(91.0/100)*(91.0/100)\n",
    "t = 1/100\n",
    "print(x*t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.73\n"
     ]
    }
   ],
   "source": [
    "perplexity = 1\n",
    "N = 0\n",
    "testset = [0, 0, 0, 0, 0, 3,0,0,0,0]\n",
    "unigram = {0:91/100, 1:1/100, 2:1/100, 3:1/100, 4:1/100,5:1/100,\n",
    "        6:1/100,7:1/100,9:1/100,9:1/100,10:1/100}\n",
    "for word in testset:\n",
    "    if word in unigram:\n",
    "        N += 1\n",
    "        perplexity = perplexity * (1/unigram[word])\n",
    "perplexity = pow(perplexity, (1/float(N)))\n",
    "\n",
    "print(\"{:0.2f}\".format(perplexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63\n"
     ]
    }
   ],
   "source": [
    "perplexity = 91/100 * 1/100\n",
    "per = pow(perplexity, (1/float(10)))\n",
    "print(\"{:0.2f}\".format(per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\\ _\n",
      "{'r u g s _': 10, 'c a t s _': 5, 'a r m s _': 5, 'f o r m _': 7, 'i _': 11}\n",
      "best=  ('s', '_')\n",
      "r\\ m\n",
      "{'r u g s_': 10, 'c a t s_': 5, 'a r m s_': 5, 'f o r m _': 7, 'i _': 11}\n",
      "best=  ('r', 'm')\n",
      "i\\ _\n",
      "{'r u g s_': 10, 'c a t s_': 5, 'a rm s_': 5, 'f o rm _': 7, 'i _': 11}\n",
      "best=  ('i', '_')\n"
     ]
    }
   ],
   "source": [
    "import re, collections\n",
    "def get_starts(vocab):\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "#         print(symbols)\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i], symbols[i+1]] += freq\n",
    "#             print(symbols[i], \" \",symbols[i+1])\n",
    "    return pairs\n",
    "def merge_vacb(pair, v_in):\n",
    "    v_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    print(bigram)\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    print(v_in)\n",
    "    for word in v_in:\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = v_in[word]\n",
    "    return v_out\n",
    "            \n",
    "vocab = {'r u g s _' : 10,'c a t s _':5,'a r m s _':5,'f o r m _':7, 'i _':11}\n",
    "merges = 3\n",
    "get_starts(vocab)\n",
    "for i in range(merges):\n",
    "    pairs = get_starts(vocab)\n",
    "    best = max(pairs, key=pairs.get)\n",
    "    vocab = merge_vacb(best, vocab)\n",
    "    \n",
    "    print(\"best= \", best)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
