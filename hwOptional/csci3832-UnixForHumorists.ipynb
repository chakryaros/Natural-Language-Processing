{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Introduction to Unix - An Exercise in Simple Word Tokenization*\n",
    "\n",
    "We'll use a collection of short stories by P.G. Wodehouse as our case study. We grabbed the collection 'The Man Upstairs and Other Stories' from Gutenberg. Let's look at the first few lines.\n",
    "\n",
    "\\* Inspired by Ken Church's Unix for Poets, Dr. Jim Martin's adaptation of the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/chakryaros/Dropbox/csci3832/hwOptional'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wodehouse_lower.txt:5:there were three distinct stages in the evolution of annette brougham's\r",
      "\r\n",
      "wodehouse_lower.txt:1061:inaudible. however, as she distinctly caught the word 'love' twice, and\r",
      "\r\n",
      "wodehouse_lower.txt:2989:'if people spoke distinct,' said the waiter, 'there wouldn't be half\r",
      "\r\n",
      "wodehouse_lower.txt:5126:ruth a human weakness for sweets, and it was with a distinct effort\r",
      "\r\n",
      "wodehouse_lower.txt:7348:'there, sir! didn't you 'ear 'im then? quite distinct it was.'\r",
      "\r\n",
      "wodehouse_lower.txt:8112:was! how soothing, if a little indistinct, his voice!\r",
      "\r\n",
      "wodehouse_lower.txt:8153:outlines of mr prosser became sharp and distinct again.\r",
      "\r\n",
      "wodehouse_lower.txt:11055:considered a distinctly furtive air about him. his eyes were too close\r",
      "\r\n",
      "wodehouse_lower.txt:11732:ordinary spectator. to the trained eye there are subtle distinctions\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!grep -nr 'distinct*' wodehouse_lower.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Common Grep Command Usage**\n",
    "\n",
    "**-n**:            Show relative line number in the file\n",
    "\n",
    "\n",
    "**'distinct*'**:   Searches for the word distinct, followed by any character\n",
    "\n",
    "\n",
    "**-r**:            Recursively search subdirectories listed\n",
    "\n",
    "\n",
    "**textFile.txt**:  Searches only in the provided textfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\r\n",
      "THE MAN UPSTAIRS\r",
      "\r\n",
      "\r",
      "\r\n",
      "\r",
      "\r\n",
      "There were three distinct stages in the evolution of Annette Brougham's\r",
      "\r\n",
      "attitude towards the knocking in the room above. In the beginning it\r",
      "\r\n",
      "had been merely a vague discomfort. Absorbed in the composition of her\r",
      "\r\n",
      "waltz, she had heard it almost subconsciously. The second stage set in\r",
      "\r\n",
      "when it became a physical pain like red-hot pincers wrenching her mind\r",
      "\r\n",
      "from her music. Finally, with a thrill in indignation, she knew it for\r",
      "\r\n",
      "cat: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "cat wodehouse.txt | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\r\n",
      "Rutherford sat on, motionless. Outside, the blackness changed to grey,\r",
      "\r\n",
      "and the grey to white. He got up. He felt very stiff and cold.\r",
      "\r\n",
      "\r",
      "\r\n",
      "'A Broadway dream!' he muttered.\r",
      "\r\n",
      "\r",
      "\r\n",
      "He went to the mantelpiece and took up the photograph. He carried it to\r",
      "\r\n",
      "the window where he could see it better.\r",
      "\r\n",
      "\r",
      "\r\n",
      "A shaft of sunlight pierced the curtains and fell upon it."
     ]
    }
   ],
   "source": [
    "cat wodehouse.txt | tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's talk about some of the commands we used here:**\n",
    "\n",
    "1. **cat**: The cat (short for “concatenate“) command is one of the most frequently used command in Linux/Unix like operating systems. cat command allows us to create single or multiple files, view contain of file, concatenate files and redirect output in terminal or files. \n",
    "\n",
    "\n",
    "2. **head**: By default the head command prints the first ten lines of a file, as we can see from the example above. If you want to print more or less than 10 lines from the beginning of the file, the head command -n option lets you specify how many lines you want to see. [Replace the first cell of code with 'cat wodehouse.txt | head -n 30' and report your results]\n",
    "\n",
    "\n",
    "3. **tail**: By default the Linux tail command also prints ten lines of a file, but it prints the last 10 lines, as we can see from the example above. The tail command has another quite useful option -f which keeps printing the end-of-file while keeping the file open (which makes it useful in examining log files)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's do a simple check by noting the total number of lines and words in the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13197  100189  574851 wodehouse.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc wodehouse.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**wc** gives us a four-columnar output - so wodehouse.txt has 13197 newlines, 100189 words and 574851 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "less wodehouse.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the above cell to examine the output from the \"less\" command. After that, try using the cat command on the same file. What do you think are the differences between 'less' and 'cat'? Understanding the differences is left as an exercise to the student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the text-oriented Unix tools are line oriented, so it would be useful to have each word on a line by itself. To do this let's do some really naïve tokenization using the 'tr' command. \n",
    "\n",
    "**How does tr work? What other options do we need?**\n",
    "\n",
    "'tr' works by taking two patterns and converts matches in the first to corresponding elements in the second.  In this case, we're using the -c option which takes the complement of the first pattern.  The -s option collapses repeated translations to a single one. In plain English that means converted anything that isn't a letter to a carriage return. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "THE\n",
      "MAN\n",
      "UPSTAIRS\n",
      "There\n",
      "were\n",
      "three\n",
      "distinct\n",
      "stages\n",
      "in\n"
     ]
    }
   ],
   "source": [
    "!tr -sc 'A-Za-z' '\\n' < wodehouse.txt | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the one word per line format we can use 'sort' to gather all instances of the same type together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "sort: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!tr -sc 'A-Za-z' '\\n' < wodehouse.txt | sort | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not all that illuminating.  Fortunately, the 'uniq' command can help. Uniq collapses repeated lines to a single line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A\n",
      "ABOUT\n",
      "ADVICE\n",
      "AGRAVAINE\n",
      "AHEAD\n",
      "ALCALA\n",
      "AND\n",
      "ANGEL\n",
      "ANSWERS\n"
     ]
    }
   ],
   "source": [
    "!tr -sc 'A-Za-z' '\\n' < wodehouse.txt | sort | uniq | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the number of lines using 'wc' will give us the size of Wodehouse's vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10252\n"
     ]
    }
   ],
   "source": [
    "!tr -sc 'A-Za-z' '\\n' < wodehouse.txt | sort | uniq | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This vocabulary size is definitely misleading since we're treating lowercase and uppercase to be the same. So, we preprocess our text (and this is going to be a large part of what we do in Natural Language Processing, preprocess text) to convert all of it to lowercase.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tr 'A-Z' 'a-z' < wodehouse.txt > wodehouse_lower1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    9597\r\n"
     ]
    }
   ],
   "source": [
    "!tr -cs \"a-z\" '\\n' < wodehouse_lower.txt | sort | uniq | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can observe that this number has reduced. It might be good to know the frequency with which he used each of those words. Fortunately, the -c option to 'uniq' that gives us the count as it collapses those repeated lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1 \n",
      "2791 a\n",
      "   2 abandon\n",
      "   1 abandoned\n",
      "   1 abashed\n",
      "   1 abbey\n",
      "   1 abducted\n",
      "   2 ability\n",
      "   1 abit\n",
      "   1 abject\n"
     ]
    }
   ],
   "source": [
    "!tr -sc 'a-z' '\\n' < wodehouse_lower.txt | sort | uniq -c | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sort this by frequency by using sort -rn which sorts in reverse numerical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4945 the\n",
      "2791 a\n",
      "2608 to\n",
      "2410 of\n",
      "2369 he\n",
      "2255 and\n",
      "2072 i\n",
      "1761 was\n",
      "1661 it\n",
      "1609 you\n",
      "sort: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!tr -sc 'a-z' '\\n' < wodehouse_lower.txt | sort | uniq -c | sort -rn | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n"
     ]
    }
   ],
   "source": [
    "!tr -sc 'a-z' '\\n' < wodehouse_lower.txt | sort | uniq -c | sort -rn | head -n 1000 > wodehouse-lower-top-1000.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very common kind of distribution called a long tail distribution. The highest frequency words are very frequent. But word frequency drops very quickly until we have a long long tail of words that have occured only one time. For word frequencies this typically corresponds to what is called a Zipf distribution. It has large implications for how we build statistical models using machine learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "lexicon = {}\n",
    "\n",
    "def loadLexicon(file):\n",
    "    for line in file:\n",
    "        count, word = line.split()\n",
    "        lexicon[word] = int(count)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loadLexicon(open('wodehouse-lower-top-1000.txt'))\n",
    "    freqs = plt.bar(range(len(lexicon.keys())), sorted(lexicon.values(), reverse=True))\n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Word frequency plot')\n",
    "    #plt.savefig(sys.stdout.buffer)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back and look at the one word per line text. Moving on to consider bigrams, we can see that each of these lines is the start of a bigram, with the second word being on the next line.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the\n",
      "man\n",
      "upstairs\n",
      "there\n",
      "were\n",
      "three\n",
      "distinct\n",
      "stages\n",
      "in\n"
     ]
    }
   ],
   "source": [
    "!tr -cs 'a-z' '\\n' < wodehouse_lower.txt | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save that to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tr -cs 'a-z' '\\n' < wodehouse_lower.txt > onewordperline.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's revisit the 'tail' command. This returns the contents of a file starting at some position.  Here we ask for the one word per line file starting at the second line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "man\n",
      "upstairs\n",
      "there\n",
      "were\n",
      "three\n",
      "distinct\n",
      "stages\n",
      "in\n",
      "the\n",
      "tail: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!tail +2 onewordperline.txt | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting this together with the paste command - voila we have our bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tthe\n",
      "the\tman\n",
      "man\tupstairs\n",
      "upstairs\tthere\n",
      "there\twere\n",
      "were\tthree\n",
      "three\tdistinct\n",
      "distinct\tstages\n",
      "stages\tin\n",
      "in\tthe\n"
     ]
    }
   ],
   "source": [
    "!tail +2 onewordperline.txt | paste onewordperline.txt - | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do our sort, uniq, sort trick on that output we get our bigram counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail +2 onewordperline.txt | paste onewordperline.txt - | sort | uniq -c | sort -rn > bigram-counts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   55151 bigram-counts.txt\n"
     ]
    }
   ],
   "source": [
    "!wc -l bigram-counts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so that's 55151 bigrams. Let's look at the counts themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 501 of\tthe\n",
      " 445 in\tthe\n",
      " 350 it\twas\n",
      " 309 on\tthe\n",
      " 298 he\thad\n",
      " 270 he\twas\n",
      " 255 to\tthe\n",
      " 237 he\tsaid\n",
      " 210 at\tthe\n",
      " 209 was\ta\n",
      " 180 don\tt\n",
      " 172 to\tbe\n",
      " 172 in\ta\n",
      " 170 of\ta\n",
      " 156 it\tis\n",
      " 154 had\tbeen\n",
      " 152 that\the\n",
      " 150 with\ta\n",
      " 144 i\tm\n",
      " 137 there\twas\n",
      " 137 i\tam\n",
      " 127 in\this\n",
      " 126 it\ts\n",
      " 124 for\tthe\n",
      " 122 i\thave\n",
      " 117 of\this\n",
      " 116 with\tthe\n",
      " 115 and\tthe\n",
      " 109 from\tthe\n",
      " 107 did\tnot\n",
      "  98 was\tnot\n",
      "  97 for\ta\n",
      "  96 one\tof\n",
      "  89 she\tsaid\n",
      "  88 she\twas\n",
      "  88 do\tyou\n",
      "  87 and\ti\n",
      "  87 a\tman\n",
      "  85 she\thad\n",
      "  84 by\tthe\n",
      "  82 was\tthe\n",
      "  81 to\thim\n",
      "  79 as\ta\n",
      "  75 and\the\n",
      "  74 that\tthe\n",
      "  73 i\tve\n",
      "  72 is\ta\n",
      "  72 i\tll\n",
      "  71 that\ti\n",
      "  71 said\tthe\n"
     ]
    }
   ],
   "source": [
    "!head -n 50 bigram-counts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In modern NLP, you would ideally do all of your analysis on your corpus after removing stopwords (and this is something we will see later in the course). So all the common words would be removed and words from which more insight can be gained will be retained. Here, we can see that most common bigrams are made up of words that are fairly common in the English lexicon."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
